{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SDG_DL",
      "provenance": [],
      "authorship_tag": "ABX9TyNqcezf5+aRBDM9g2d+JiK2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyb09/soumyb09/blob/master/SDG_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0PWhCbMkgYy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "beebce67-6391-412c-d367-2bcfe8950fed"
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, Dropout, MaxPool2D, Dense, Flatten, Input\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.utils import to_categorical\n",
        "import keras.backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N3yV8o-kyRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5c7faf04-34d3-447b-8844-f3d619cf5d24"
      },
      "source": [
        "(_,_),(x_train,y_train)=mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfcL0flglNQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYM7woe1lRX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=x_train.reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgmbEjyUmNJr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5aa987aa-e94b-4ee5-d3af-7e2a215a2012"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q50RidUmP4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90e38292-1517-4a05-f13c-6a79734d55f8"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GskMlx6xmTWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=to_categorical(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dECRIrMimciZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "3153e0fc-9f48-4119-9abf-edfd6be5a784"
      },
      "source": [
        "K.clear_session()\n",
        "inp = Input(shape=(28,28,1), dtype=np.float32)\n",
        "x = Conv2D(filters=16,kernel_size=3,strides=1,padding='same')(inp)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = Conv2D(filters=32,kernel_size=3,strides=1,padding='same')(inp)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = Conv2D(filters=64,kernel_size=3,strides=1,padding='same')(inp)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = MaxPool2D(pool_size=2, padding='same')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(units=64)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = Dense(units=32)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dense(units=10)(x)\n",
        "out=Activation('softmax')(x)\n",
        "model = Model(inp,out)\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwqCglQ0sDff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "aea030de-2809-4c78-b63c-5075d69baf04"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                802880    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 806,570\n",
            "Trainable params: 806,250\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HcKlGf-sGgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b37c627b-ca6d-4105-ea30-731d6f197697"
      },
      "source": [
        "model.fit(x=x_train,y=y_train,batch_size=32,epochs=30, validation_split=0.4)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 36000 samples, validate on 24000 samples\n",
            "Epoch 1/30\n",
            "36000/36000 [==============================] - 123s 3ms/step - loss: 0.3365 - acc: 0.9163 - val_loss: 0.1256 - val_acc: 0.9660\n",
            "Epoch 2/30\n",
            "36000/36000 [==============================] - 120s 3ms/step - loss: 0.1287 - acc: 0.9628 - val_loss: 0.1411 - val_acc: 0.9576\n",
            "Epoch 3/30\n",
            "36000/36000 [==============================] - 122s 3ms/step - loss: 0.0997 - acc: 0.9690 - val_loss: 0.0729 - val_acc: 0.9786\n",
            "Epoch 4/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0828 - acc: 0.9748 - val_loss: 0.0787 - val_acc: 0.9763\n",
            "Epoch 5/30\n",
            "36000/36000 [==============================] - 122s 3ms/step - loss: 0.0710 - acc: 0.9774 - val_loss: 0.0908 - val_acc: 0.9726\n",
            "Epoch 6/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0618 - acc: 0.9808 - val_loss: 0.0677 - val_acc: 0.9792\n",
            "Epoch 7/30\n",
            "36000/36000 [==============================] - 122s 3ms/step - loss: 0.0581 - acc: 0.9819 - val_loss: 0.0731 - val_acc: 0.9788\n",
            "Epoch 8/30\n",
            "36000/36000 [==============================] - 122s 3ms/step - loss: 0.0503 - acc: 0.9838 - val_loss: 0.0677 - val_acc: 0.9806\n",
            "Epoch 9/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0458 - acc: 0.9856 - val_loss: 0.0713 - val_acc: 0.9794\n",
            "Epoch 10/30\n",
            "36000/36000 [==============================] - 122s 3ms/step - loss: 0.0444 - acc: 0.9854 - val_loss: 0.0656 - val_acc: 0.9810\n",
            "Epoch 11/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0403 - acc: 0.9863 - val_loss: 0.0631 - val_acc: 0.9823\n",
            "Epoch 12/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0383 - acc: 0.9873 - val_loss: 0.0606 - val_acc: 0.9830\n",
            "Epoch 13/30\n",
            "36000/36000 [==============================] - 122s 3ms/step - loss: 0.0343 - acc: 0.9881 - val_loss: 0.0633 - val_acc: 0.9825\n",
            "Epoch 14/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0328 - acc: 0.9892 - val_loss: 0.0779 - val_acc: 0.9789\n",
            "Epoch 15/30\n",
            "36000/36000 [==============================] - 122s 3ms/step - loss: 0.0316 - acc: 0.9891 - val_loss: 0.0593 - val_acc: 0.9842\n",
            "Epoch 16/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0290 - acc: 0.9909 - val_loss: 0.0581 - val_acc: 0.9837\n",
            "Epoch 17/30\n",
            "36000/36000 [==============================] - 122s 3ms/step - loss: 0.0287 - acc: 0.9907 - val_loss: 0.0689 - val_acc: 0.9814\n",
            "Epoch 18/30\n",
            "36000/36000 [==============================] - 124s 3ms/step - loss: 0.0245 - acc: 0.9915 - val_loss: 0.0683 - val_acc: 0.9821\n",
            "Epoch 19/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0242 - acc: 0.9920 - val_loss: 0.0615 - val_acc: 0.9836\n",
            "Epoch 20/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0252 - acc: 0.9914 - val_loss: 0.0573 - val_acc: 0.9846\n",
            "Epoch 21/30\n",
            "36000/36000 [==============================] - 122s 3ms/step - loss: 0.0219 - acc: 0.9929 - val_loss: 0.0692 - val_acc: 0.9815\n",
            "Epoch 22/30\n",
            "36000/36000 [==============================] - 120s 3ms/step - loss: 0.0254 - acc: 0.9915 - val_loss: 0.0590 - val_acc: 0.9850\n",
            "Epoch 23/30\n",
            "36000/36000 [==============================] - 122s 3ms/step - loss: 0.0220 - acc: 0.9927 - val_loss: 0.0673 - val_acc: 0.9824\n",
            "Epoch 24/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0215 - acc: 0.9925 - val_loss: 0.0635 - val_acc: 0.9841\n",
            "Epoch 25/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0223 - acc: 0.9922 - val_loss: 0.0588 - val_acc: 0.9847\n",
            "Epoch 26/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0210 - acc: 0.9932 - val_loss: 0.0626 - val_acc: 0.9833\n",
            "Epoch 27/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0219 - acc: 0.9921 - val_loss: 0.0590 - val_acc: 0.9843\n",
            "Epoch 28/30\n",
            "36000/36000 [==============================] - 122s 3ms/step - loss: 0.0201 - acc: 0.9936 - val_loss: 0.0554 - val_acc: 0.9847\n",
            "Epoch 29/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0187 - acc: 0.9936 - val_loss: 0.0643 - val_acc: 0.9838\n",
            "Epoch 30/30\n",
            "36000/36000 [==============================] - 121s 3ms/step - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0568 - val_acc: 0.9847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1f7f812a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRfer9Lcur1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test=x_test.reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhI74jTUsGrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds=model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jojLhnp7sGn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5accc481-e2de-4562-9d92-c7a539388e85"
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpDMev8QsGmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat=np.argmax(preds,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSzyLAnxsGkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "afc5b201-c0c4-4156-f612-ed4ca1c891c5"
      },
      "source": [
        "import pandas as pd\n",
        "pd.crosstab(y_test,y_hat)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>973</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1132</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>1011</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>993</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>965</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>881</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>944</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1012</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>964</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    0     1     2    3    4    5    6     7    8    9\n",
              "row_0                                                     \n",
              "0      973     0     1    0    0    0    4     1    1    0\n",
              "1        0  1132     2    0    0    0    0     1    0    0\n",
              "2        4     9  1011    0    0    0    1     6    0    1\n",
              "3        0     0     4  993    0    3    2     5    2    1\n",
              "4        0     0     0    0  965    0    5     0    1   11\n",
              "5        1     1     1    4    0  881    4     0    0    0\n",
              "6        5     4     0    0    1    2  944     0    2    0\n",
              "7        0     4    11    0    0    0    0  1012    1    0\n",
              "8        2     1     2    0    0    1    1     2  964    1\n",
              "9        1     1     1    2    3    4    0     7    4  986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}